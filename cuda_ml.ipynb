{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LiEsn8gJJlmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0d3135-157b-4e56-a54b-f211b4e26974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2022.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.2.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2022.1.12)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (2.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.8.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipytest in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ipytest) (21.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.9.0)\n",
            "Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.7/dist-packages (from ipytest) (7.1.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (2.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (4.12.0)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (1.11.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5.4->ipytest) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest>=5.4->ipytest) (3.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.18.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipytest) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipytest) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipytest) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->ipytest) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipytest) (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda\n",
        "!pip install tensorflow #only for getting data\n",
        "!pip install ipytest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w4PYMj9Sa4VI"
      },
      "outputs": [],
      "source": [
        "import pycuda.compiler as comp\n",
        "import pycuda.driver as cuda\n",
        "import numpy\n",
        "import pycuda.autoinit\n",
        "import time\n",
        "import math\n",
        "from tensorflow import keras\n",
        "from os.path import exists\n",
        "\n",
        "#pip install pycuda\n",
        "#pip install tensorflow\n",
        "\n",
        "class Net():\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "    def setSize(self, layers):\n",
        "      self.layers = layers\n",
        "      self.numberOfNodes = 0\n",
        "      for i in range(len(self.layers)):\n",
        "        self.numberOfNodes += self.layers[i]\n",
        "\n",
        "      self.nodesGrad = numpy.zeros((self.numberOfNodes, 1),dtype=numpy.float32)\n",
        "      self.nodes = numpy.zeros((self.numberOfNodes, 1),dtype=numpy.float32)\n",
        "      self.loss = numpy.zeros((self.numberOfNodes, 1),dtype=numpy.float32)\n",
        "\n",
        "      self.numberOfWeights = 0\n",
        "      for i in range(len(self.layers)-1):\n",
        "        self.numberOfWeights += self.layers[i] * self.layers[i+1]\n",
        "\n",
        "      self.grads = numpy.zeros((self.numberOfWeights, 1),dtype=numpy.float32)\n",
        "      self.weights = numpy.zeros((self.numberOfWeights, 1),dtype=numpy.float32)\n",
        "      self.weightsLoss = numpy.zeros((self.numberOfWeights, 1),dtype=numpy.float32)\n",
        "\n",
        "    def copyToDevice(self):\n",
        "      self.weights_gpu = cuda.mem_alloc(self.weights.nbytes)\n",
        "      cuda.memcpy_htod(self.weights_gpu,self.weights)\n",
        "      self.nodes_gpu = cuda.mem_alloc(self.nodes.nbytes)\n",
        "      cuda.memcpy_htod(self.nodes_gpu,self.nodes)\n",
        "      self.grads_gpu = cuda.mem_alloc(self.grads.nbytes)\n",
        "      cuda.memcpy_htod(self.grads_gpu,self.grads)\n",
        "      self.nodesGrad_gpu = cuda.mem_alloc(self.nodesGrad.nbytes)\n",
        "      cuda.memcpy_htod(self.nodesGrad_gpu,self.nodesGrad)\n",
        "      self.loss_gpu = cuda.mem_alloc(self.loss.nbytes)\n",
        "      cuda.memcpy_htod(self.loss_gpu,self.loss)\n",
        "\n",
        "      self.weightsLoss_gpu = cuda.mem_alloc(self.weightsLoss.nbytes)\n",
        "      cuda.memcpy_htod(self.weightsLoss_gpu,self.weightsLoss)\n",
        "\n",
        "    def loadWeights(self, path):\n",
        "      weightsFile = path\n",
        "      for i in range(len(self.layers) - 1):\n",
        "        weightsFile += str(self.layers[i]) + \"-\"\n",
        "      weightsFile += str(self.layers[len(self.layers)-1]) + \".txt\"\n",
        "      if exists(weightsFile):\n",
        "        f = open(weightsFile, \"r\")\n",
        "        lines = f.readlines()\n",
        "        for i in range(len(lines)):\n",
        "          line = lines[i].replace(\"\\n\",\"\")\n",
        "          self.weights[i] = line\n",
        "\n",
        "      else:\n",
        "        print(\"no weights file was found\")    \n",
        "        for x in range(len(self.weights)):\n",
        "          self.weights[x] = numpy.random.uniform() * (2 / numpy.sqrt(self.layers[0])) - 1 / numpy.sqrt(self.layers[0])\n",
        "\n",
        "    def optimize(self):\n",
        "      length = len(self.weights)\n",
        "      bx,by,gx,gy = self.getBlockAndGridSize(length,1)\n",
        "      optimize(self.weights_gpu, self.grads_gpu,self.learningRate, numpy.int32(length), block=(bx,by,1),grid=(gx,gy))\n",
        "\n",
        "    def zero_grad(self):\n",
        "      length = len(self.weights)\n",
        "      bx,by,gx,gy = self.getBlockAndGridSize(length,1)\n",
        "      reset_values(self.grads_gpu,numpy.int32(length),block=(bx,by,1),grid=(gx,gy))\n",
        "  \n",
        "    def backward(self):\n",
        "      length = len(self.nodesGrad)\n",
        "\n",
        "      bx,by,gx,gy = self.getBlockAndGridSize(length,1)\n",
        "\n",
        "      der_sigmoid(self.nodesGrad_gpu,self.nodes_gpu, numpy.int32(length),block=(bx,by,1),grid=(gx,gy))\n",
        "\n",
        "      numberOfLayers = len(self.layers)\n",
        "\n",
        "      startw0 = numpy.int32(len(self.weights) - (self.layers[numberOfLayers-1] * self.layers[numberOfLayers-2]))\n",
        "      startn1 = numpy.int32(self.numberOfNodes - self.layers[numberOfLayers-1])\n",
        "      startn0 = startn1 - numpy.int32(self.layers[numberOfLayers-2])\n",
        "      lengthn0 = self.layers[numberOfLayers-2]\n",
        "      lengthn1 = self.layers[numberOfLayers-1]\n",
        "      lengthw1 = self.layers[numberOfLayers-2] * self.layers[numberOfLayers-1]\n",
        "\n",
        "      ###---------------------------\n",
        "\n",
        "      start = startn1\n",
        "      check_answer(training_correct_gpu, self.nodes_gpu, start, numpy.int32(label_train[i]),block=(1,1,1))\n",
        "\n",
        "      #backward\n",
        "      start = startn1\n",
        "      lengthx = lengthn1\n",
        "      lengthy = 1\n",
        "\n",
        "      bx,by,gx,gy = self.getBlockAndGridSize(lengthx,lengthy)\n",
        "\n",
        "      get_output_loss(self.loss_gpu, self.nodes_gpu, start, numpy.int32(label_train[i]),\n",
        "                      block=(bx,by,1),grid=(gx,gy))\n",
        "      \n",
        "      lengthx = lengthn0\n",
        "      lengthy = lengthn1\n",
        "\n",
        "      bx,by,gx,gy = self.getBlockAndGridSize(lengthx,lengthy)\n",
        "\n",
        "      #int ncA, int ncB, int nrA\n",
        "      startC = startn0\n",
        "      startD = startw0\n",
        "      startA = startn1\n",
        "      startB = startA\n",
        "      ncB = numpy.int32(lengthn0)\n",
        "      nrA = numpy.int32(lengthn1)\n",
        "      #__global__ void multiply_them_index_minus(float *d, float *a, float *b ,float *c, int startA, int startB, int startC, int startD, int ncB, int nrA)\n",
        "      multiply_them_index_add(self.grads_gpu, self.loss_gpu, self.nodesGrad_gpu,\n",
        "       self.nodes_gpu, startA, startB, startC, startD, ncB, nrA,\n",
        "        block=(bx,by,1), grid=(gx,gy)) \n",
        "      \n",
        "      #backward first weights ???\n",
        "      startw1 = numpy.int32(len(self.weights))\n",
        "      for y in range(len(self.layers)-2):\n",
        "\n",
        "        startw1 -= numpy.int32(self.layers[numberOfLayers-1-y] * self.layers[numberOfLayers-2-y])\n",
        "        startw0 -= numpy.int32(self.layers[numberOfLayers-2-y] * self.layers[numberOfLayers-3-y])\n",
        "\n",
        "        startn1 -= numpy.int32(self.layers[numberOfLayers-2-y])\n",
        "        startn0 -= numpy.int32(self.layers[numberOfLayers-3-y])\n",
        "\n",
        "        lengthn0 = self.layers[numberOfLayers-3-y]\n",
        "        lengthn1 = self.layers[numberOfLayers-2-y]\n",
        "        lengthn2 = self.layers[numberOfLayers-1-y]\n",
        "\n",
        "        lengthw1 = self.layers[numberOfLayers-3-y] * self.layers[numberOfLayers-2-y]\n",
        "        #print(\"lengthw1 =\",lengthw1)\n",
        "\n",
        "        length = lengthw1\n",
        "        bx = length\n",
        "        gx = 1\n",
        "        if bx > MAX_THREADS_PER_BLOCK:\n",
        "          gx = int(bx / MAX_THREADS_PER_BLOCK) + 1\n",
        "          bx = MAX_THREADS_PER_BLOCK\n",
        "        startD = startn1\n",
        "        startA = startw1\n",
        "        startB = startw1\n",
        "        array_mulitply(self.weightsLoss_gpu,self.weights_gpu,self.grads_gpu,startD,startA,startB,numpy.int32(length)\n",
        "        ,block=(bx,1,1),grid=(gx,1))\n",
        "\n",
        "        startA = startn1\n",
        "        length = lengthn1\n",
        "        startD = startn0\n",
        "        bx = length\n",
        "        gx = 1\n",
        "        if bx > MAX_THREADS_PER_BLOCK:\n",
        "          gx = int(bx / MAX_THREADS_PER_BLOCK) + 1\n",
        "          bx = MAX_THREADS_PER_BLOCK\n",
        "        numberOfNodesInLayer = numpy.int32(lengthn2)\n",
        "        get_node_loss(self.loss_gpu,self.weightsLoss_gpu,numberOfNodesInLayer,startA,startD,\n",
        "                      numpy.int32(length),block=(bx,1,1),grid=(gx,1))\n",
        "\n",
        "        startA = startn0\n",
        "        startB = startn1\n",
        "        startC = startn0\n",
        "        startD = startw0\n",
        "\n",
        "        lengthx = lengthn0\n",
        "        lengthy = lengthn1\n",
        "\n",
        "        bx,by,gx,gy = self.getBlockAndGridSize(lengthx,lengthy)\n",
        "\n",
        "        multiply_them_index_add(self.grads_gpu,self.loss_gpu,self.nodesGrad_gpu, self.nodes_gpu,startA,startB,startC,startD,numpy.int32(lengthx),numpy.int32(lengthy),\n",
        "                  block=(bx,by,1),grid=(gx,gy))\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "      #copy input (n0_gpu) to nodes_gpu\n",
        "      length = self.layers[0]\n",
        "\n",
        "      bx,by,gx,gy = self.getBlockAndGridSize(length,1)\n",
        "  \n",
        "      copy(self.nodes_gpu, input, numpy.int32(0), numpy.int32(0), numpy.int32(length), block=(bx,by,1), grid=(gx,gy))\n",
        "\n",
        "      startn0 = numpy.int32(0)\n",
        "      startn1 = numpy.int32(self.layers[0])\n",
        "      startw = numpy.int32(0)\n",
        "      start = numpy.int32(0)\n",
        "      for x in range(len(self.layers)-1):\n",
        "        \n",
        "        if x > 0:\n",
        "          startw += numpy.int32(self.layers[x-1] * self.layers[x])\n",
        "          startn1 += numpy.int32(self.layers[x])\n",
        "          startn0 += numpy.int32(self.layers[x-1])\n",
        "\n",
        "\n",
        "        n = self.layers[x] # number of columns in A / number of rows in B\n",
        "        n_NP = numpy.int32(n)\n",
        "        nrA = numpy.int32(self.layers[x+1])\n",
        "\n",
        "        bx,by,gx,gy = self.getBlockAndGridSize(1,self.layers[x+1]) # number of cols in B, number of rows in A\n",
        "\n",
        "        multiply_them_index(self.nodes_gpu, self.weights_gpu, self.nodes_gpu, n_NP, numpy.int32(bx) \n",
        "        ,nrA , startn0, startn1,\n",
        "                              startw, block=(bx,by,1), grid=(gx,gy))\n",
        "\n",
        "        length = self.layers[x+1]\n",
        "        start += numpy.int32(self.layers[x])\n",
        "\n",
        "        bx,by,gx,gy = self.getBlockAndGridSize(length,1)\n",
        "\n",
        "        sigmoid_index(self.nodes_gpu,start,numpy.int32(length),\n",
        "                      block=(bx,by,1), grid=(gx,gy))\n",
        "\n",
        "\n",
        "      return 0\n",
        "\n",
        "    def getBlockAndGridSize(self,lengthx,lengthy):\n",
        "      bx = lengthx\n",
        "      by = lengthy\n",
        "      gx = 1\n",
        "      gy = 1\n",
        "      if bx > MAX_THREADS_PER_BLOCK:\n",
        "        gx = math.ceil(bx / MAX_THREADS_PER_BLOCK)\n",
        "        bx = MAX_THREADS_PER_BLOCK\n",
        "\n",
        "      if by > MAX_THREADS_PER_BLOCK:\n",
        "        gy = math.ceil(by / MAX_THREADS_PER_BLOCK)\n",
        "        by = MAX_THREADS_PER_BLOCK\n",
        "\n",
        "      if bx * by > MAX_THREADS_PER_BLOCK:\n",
        "        if by > bx:\n",
        "          bx = math.ceil(MAX_THREADS_PER_BLOCK / by)\n",
        "          gx = math.ceil(lengthx / bx)\n",
        "        else:\n",
        "          by = int(MAX_THREADS_PER_BLOCK / bx)\n",
        "          gy = math.ceil(lengthy / by) \n",
        "      return bx,by,gx,gy\n",
        "\n",
        "mod = comp.SourceModule(\n",
        "    \"\"\"\n",
        "  __global__ void multiply_them_index(float *nodesD, float *weights, float *nodesA, int ncA, int ncB, int nrA, int startn0, int startD, int startW)\n",
        "{\n",
        "  int row = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "  int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "  float t = 0;\n",
        "  if(col < ncB && row < nrA)\n",
        "  {\n",
        "  for(int i = 0; i < ncA; i++){\n",
        "    t += weights[startW + (row * ncA) + i] * nodesA[startn0 + col + (i * ncB)];\n",
        "  }\n",
        "    nodesD[startD + (row * ncB) + col] = t;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void multiply_them_index_add(float *d, float *a, float *b ,float *c, int startA, int startB, int startC, int startD, int ncB, int nrA)\n",
        "{\n",
        "  int row = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "  int col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "  if(col < ncB && row < nrA)\n",
        "  {\n",
        "    d[startD + (row * ncB) + col] += a[startA + row] * b[startB + row] * c[startC + col];\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void optimize(float *d, float *a, float lr, int length)\n",
        "{\n",
        "  int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if(i < length)\n",
        "  {\n",
        "  d[i] = (lr * -a[i]) + d[i];\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void array_mulitply(float *d, float *a, float *b, int startD, int startA, int startB, int length)\n",
        "{\n",
        "  const int i = threadIdx.x + (blockDim.x * blockIdx.x);\n",
        "  if(i < length)\n",
        "  {\n",
        "  d[startD + i] = a[startA + i] * b[startB + i];\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void get_output_loss(float *d, float *o, int start, int a)\n",
        "{\n",
        "  int i = threadIdx.x;\n",
        "  if(i == a) {\n",
        "    d[start + i] = o[start + i] - 1;\n",
        "  } else {\n",
        "    d[start + i] = o[start + i];\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void get_node_loss(float *d, float *a, int n, int startA, int startD, int length)\n",
        "{\n",
        "  int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "  float t = 0;\n",
        "  for(int j = 0; j < n; j++) \n",
        "  {\n",
        "    if(i < length)\n",
        "    {\n",
        "    t += a[startA + i + j*length];\n",
        "    }\n",
        "  }\n",
        "  if(i < length)\n",
        "  { \n",
        "  d[startD + i] = t / n;\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void reset_values(float *d, int length)\n",
        "{\n",
        "  int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "  if(i < length)\n",
        "  {\n",
        "    d[i] = 0;\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void check_answer(int *a, float *output, int start,int answer)\n",
        "{\n",
        "  for(int i = 0; i < 10; i++)\n",
        "  {\n",
        "    if(output[start + i] > output[start + answer])\n",
        "    {\n",
        "      return;\n",
        "    }\n",
        "  }\n",
        "  a[0] = a[0] + 1;\n",
        "}\n",
        "\n",
        "__global__ void sigmoid_index(float *d, int start, int length)\n",
        "{\n",
        "  const int i = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "  if(i < length)\n",
        "  {\n",
        "    d[start + i] = 1 / (1 + exp(-d[start + i]));\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void der_sigmoid(float *d, float *a, int length)\n",
        "{\n",
        "  const int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if(i < length)\n",
        "  {\n",
        "    d[i] = a[i] * (1 - a[i]);\n",
        "  }\n",
        "}\n",
        "\n",
        "__global__ void copy(float *d, float *a, int startA, int startD, int length)\n",
        "{\n",
        "  int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  if(i < length)\n",
        "  {\n",
        "    d[i + startD] = a[i + startA];\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "MAX_THREADS_PER_BLOCK = \\\n",
        "    cuda.Device(0).get_attribute(pycuda._driver.device_attribute.MAX_THREADS_PER_BLOCK)\n",
        "\n",
        "multiply_them_index = mod.get_function(\"multiply_them_index\")\n",
        "multiply_them_index_add = mod.get_function(\"multiply_them_index_add\") #adds to result\n",
        "optimize = mod.get_function(\"optimize\")\n",
        "sigmoid_index = mod.get_function(\"sigmoid_index\")\n",
        "der_sigmoid = mod.get_function(\"der_sigmoid\")\n",
        "array_mulitply = mod.get_function(\"array_mulitply\")\n",
        "get_output_loss = mod.get_function(\"get_output_loss\")\n",
        "get_node_loss = mod.get_function(\"get_node_loss\")\n",
        "reset_values = mod.get_function(\"reset_values\")\n",
        "check_answer = mod.get_function(\"check_answer\")\n",
        "copy = mod.get_function(\"copy\")\n",
        "\n",
        "def test(testNet):\n",
        "  reset_values(test_correct_gpu,numpy.int32(1),block=(1,1,1))\n",
        "  start_time = time.time()\n",
        "  start = numpy.int32(0)\n",
        "  for x in range(len(testNet.layers)-1):\n",
        "    start += numpy.int32(testNet.layers[x])\n",
        "  for i in range(len(img_test)):\n",
        "    testImg32 = img_test[i].astype(numpy.float32)  \n",
        "    cuda.memcpy_htod(img_gpu, testImg32)\n",
        "\n",
        "    testNet.forward(img_gpu)\n",
        "    check_answer(test_correct_gpu, testNet.nodes_gpu, start, numpy.int32(label_test[i]),block=(1,1,1))\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  cuda.memcpy_dtoh(test_correct,test_correct_gpu)\n",
        "  print(\"test dataset: correct = \",(test_correct[0]/len(img_test)))\n",
        "\n",
        "#---- mnist stuff ---- \n",
        "\n",
        "(img_train, label_train), (img_test, label_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "img_train = img_train / 255\n",
        "img_test = img_test / 255\n",
        "\n",
        "training_correct = numpy.zeros((1),dtype=numpy.int32)\n",
        "training_correct_gpu = cuda.mem_alloc(training_correct.nbytes)\n",
        "cuda.memcpy_htod(training_correct_gpu,training_correct)\n",
        "\n",
        "test_correct = numpy.zeros((1),dtype=numpy.int32)\n",
        "test_correct_gpu = cuda.mem_alloc(test_correct.nbytes)\n",
        "cuda.memcpy_htod(test_correct_gpu,test_correct)\n",
        "\n",
        "trainImg32 = img_train[0].astype(numpy.float32)\n",
        "img_gpu = cuda.mem_alloc(trainImg32.nbytes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testNet = Net()\n",
        "\n",
        "testNet.setSize([784,16,10])\n",
        "\n",
        "#weightsFile = \"sigmoid-weights\"\n",
        "weightsFile = \"sigmoid-untrained-weights\"\n",
        "testNet.loadWeights(weightsFile)\n",
        "testNet.learningRate = numpy.float32(0.1)\n",
        "testNet.copyToDevice()\n",
        "\n",
        "batchSize = 1\n",
        "for epoch in range(1):\n",
        "  print(\"\\nEPOCH\",epoch,\"\\n\")\n",
        "  start_time = time.time()\n",
        "  for i in range(len(img_train)): \n",
        "    trainImg32 = img_train[i].astype(numpy.float32)\n",
        "    cuda.memcpy_htod(img_gpu,trainImg32)\n",
        "\n",
        "    testNet.forward(img_gpu)\n",
        "\n",
        "    testNet.backward()\n",
        "    \n",
        "    if i % batchSize == 0 or i == (len(img_train) - 1):\n",
        "      testNet.optimize()      \n",
        "      testNet.zero_grad()  \n",
        "\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  cuda.memcpy_dtoh(training_correct,training_correct_gpu)\n",
        "  reset_values(training_correct_gpu,numpy.int32(1),block=(1,1,1))\n",
        "  print(\"train dataset: correct = \",(training_correct[0]/len(img_train)))\n",
        "  test(testNet)\n",
        "  assert test_correct[0]/len(img_test) == 0.8948,\"test accuracy has changed.\"\n",
        "\n",
        "testNet = Net()\n",
        "testNet.setSize([784,4,10]) \n",
        "#weightsFile = \"sigmoid-weights\"\n",
        "weightsFile = \"sigmoid-untrained-weights\"\n",
        "testNet.loadWeights(weightsFile)\n",
        "testNet.learningRate = numpy.float32(0.1)\n",
        "testNet.copyToDevice()\n",
        "\n",
        "\n",
        "batchSize = 1\n",
        "for epoch in range(1):\n",
        "  print(\"\\nEPOCH\",epoch,\"\\n\")\n",
        "  start_time = time.time()\n",
        "  for i in range(len(img_train)): \n",
        "    trainImg32 = img_train[i].astype(numpy.float32)\n",
        "    cuda.memcpy_htod(img_gpu,trainImg32)\n",
        "\n",
        "    testNet.forward(img_gpu)\n",
        "\n",
        "    testNet.backward()\n",
        "    \n",
        "    if i % batchSize == 0 or i == (len(img_train) - 1):\n",
        "      testNet.optimize()      \n",
        "      testNet.zero_grad()  \n",
        "\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  cuda.memcpy_dtoh(training_correct,training_correct_gpu)\n",
        "  reset_values(training_correct_gpu,numpy.int32(1),block=(1,1,1))\n",
        "  print(\"train dataset: correct = \",(training_correct[0]/len(img_train)))\n",
        "  test(testNet)\n",
        "  assert test_correct[0]/len(img_test) == 0.7046,\"test accuracy has changed.\"\n",
        "\n",
        "testNet = Net()\n",
        "testNet.learningRate = numpy.float32(0.1)\n",
        "testNet.setSize([784,1200,10])\n",
        "#weightsFile = \"sigmoid-weights\"\n",
        "testNet.loadWeights(\"sigmoid-untrained-weights\")\n",
        "testNet.copyToDevice()\n",
        "\n",
        "batchSize = 1\n",
        "for epoch in range(1):\n",
        "  print(\"\\nEPOCH\",epoch,\"\\n\")\n",
        "  start_time = time.time()\n",
        "  for i in range(10000): \n",
        "    trainImg32 = img_train[i].astype(numpy.float32)\n",
        "    cuda.memcpy_htod(img_gpu,trainImg32)\n",
        "\n",
        "    testNet.forward(img_gpu)\n",
        "\n",
        "    testNet.backward()\n",
        "    \n",
        "    if i % batchSize == 0 or i == (len(img_train) - 1):\n",
        "      testNet.optimize()      \n",
        "      testNet.zero_grad()  \n",
        "\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  cuda.memcpy_dtoh(training_correct,training_correct_gpu)\n",
        "  reset_values(training_correct_gpu,numpy.int32(1),block=(1,1,1))\n",
        "  print(\"train dataset: correct = \",(training_correct[0]/len(img_train)))\n",
        "  test(testNet)\n",
        "  assert test_correct[0]/len(img_test) == 0.593,\"test accuracy has changed.\"\n",
        "\n",
        "testNet = Net()\n",
        "testNet.learningRate = numpy.float32(1)\n",
        "testNet.setSize([784,16,10,10]) \n",
        "#weightsFile = \"sigmoid-weights\"\n",
        "testNet.loadWeights(\"sigmoid-untrained-weights\")\n",
        "testNet.copyToDevice()\n",
        "\n",
        "batchSize = 1\n",
        "for epoch in range(1):\n",
        "  print(\"\\nEPOCH\",epoch,\"\\n\")\n",
        "  start_time = time.time()\n",
        "  for i in range(len(img_train)): \n",
        "    trainImg32 = img_train[i].astype(numpy.float32)\n",
        "    cuda.memcpy_htod(img_gpu,trainImg32)\n",
        "\n",
        "    testNet.forward(img_gpu)\n",
        "\n",
        "    testNet.backward()\n",
        "    \n",
        "    if i % batchSize == 0 or i == (len(img_train) - 1):\n",
        "      testNet.optimize()      \n",
        "      testNet.zero_grad()  \n",
        "\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  cuda.memcpy_dtoh(training_correct,training_correct_gpu)\n",
        "  reset_values(training_correct_gpu,numpy.int32(1),block=(1,1,1))\n",
        "  print(\"train dataset: correct = \",(training_correct[0]/len(img_train)))\n",
        "  test(testNet)\n",
        "  assert test_correct[0]/len(img_test) == 0.8181,\"test accuracy has changed.\""
      ],
      "metadata": {
        "id": "cjbZ9Crl8w6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28cd4ccc-0a03-4039-d3db-324446e8544e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH 0 \n",
            "\n",
            "--- 16.592320442199707 seconds ---\n",
            "train dataset: correct =  0.7494\n",
            "--- 0.9764716625213623 seconds ---\n",
            "test dataset: correct =  0.8948\n",
            "\n",
            "EPOCH 0 \n",
            "\n",
            "--- 13.112079620361328 seconds ---\n",
            "train dataset: correct =  0.54315\n",
            "--- 0.9895646572113037 seconds ---\n",
            "test dataset: correct =  0.7046\n",
            "\n",
            "EPOCH 0 \n",
            "\n",
            "--- 13.983998537063599 seconds ---\n",
            "train dataset: correct =  0.06421666666666667\n",
            "--- 7.213452577590942 seconds ---\n",
            "test dataset: correct =  0.593\n",
            "\n",
            "EPOCH 0 \n",
            "\n",
            "--- 17.748128175735474 seconds ---\n",
            "train dataset: correct =  0.43998333333333334\n",
            "--- 1.3187968730926514 seconds ---\n",
            "test dataset: correct =  0.8181\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}